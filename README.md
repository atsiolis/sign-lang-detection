# Sign Language Detection

This project aims to develop a system for detecting and interpreting sign language gestures using machine learning techniques.

## Introduction
Sign language detection is a crucial technology that can bridge the communication gap between the hearing and the deaf or hard-of-hearing communities. This project leverages computer vision and deep learning to recognize and translate sign language gestures into text.

## Features
- Real-time sign language detection
- High accuracy gesture recognition
- User-friendly interface

## Dataset
The dataset used for this project is sourced from Kaggle and can be found [here](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). It contains images of the American Sign Language (ASL) alphabet, which are used to train and test the machine learning models.

## Hand Tracking with MediaPipe
This project utilizes MediaPipe for hand tracking. MediaPipe is a cross-platform framework for building multimodal applied machine learning pipelines. It provides fast and accurate hand tracking, which is essential for detecting sign language gestures.

